ALTERNATIVE ACCOUNT OF EXPLANATORY EFFICIENCY 

A continuation of the earlier case will make it clear what this means and why it matters. Why doesn't the outcome change under the given conditions? Because, says the standard account, the key factor remained in place. But, the skeptic will counter, perhaps we can discard that account; perhaps there's an alternative that fits the observations equally well. But, I would respond, even granting for argument's sake that such an alternative exists, it doesn't follow that it avoids more gaps than the one it replaces. It doesn't follow that it is comparable from a trade-off standpoint to the original—that it reduces as many issues as the old view while introducing no more new ones. In fact, the opposite often holds. Consider the alternative mentioned earlier. The cost of that account—meaning what new puzzles it creates—is vastly greater than its value—meaning what old puzzles it removes. It would be difficult to devise an account inconsistent with the conventional one that, while still matching the relevant evidence, is equally efficient in explanatory terms. You can test this for yourself. If there is reason to think even one such account exists, it is not because it has ever been produced. That reason, if it exists, must be purely theoretical. And for reasons soon to be made clear, no such purely theoretical reason can justify accepting it. But there is a further difficulty for this—or, by a similar line of thought, for any non-standard—replacement of the conventional view. It is not at all clear that, once the relevant details are considered, the replacement is even logically possible. Taken on its own, a substitute account may describe a situation that seems coherent. It may not be contradictory in the strict sense. But that alone is not enough for it to serve as a viable model of the relevant information. Think of the range of underlying principles that would have to be set aside. Setting them aside, if possible at all, would create ripple effects. Consider the various interactions that would be altered, the balances disrupted, the exchanges prevented. Those interactions do not only sustain the single feature in question. Removing them would have many other consequences—events unrelated to the specific aim of the new model. And there is no assurance that these other consequences would be compatible, even in a purely formal sense, with the data the new account is supposed to capture as well as the conventional one it seeks to replace.

EPISTEMOLOGY 

RATIONAL BELIEF AND UNDERLYING STRUCTURE 

When would it become rational to believe that, next time, you're more likely than not to roll this as opposed to that number—that, for example, you're especially likely to roll a 27? This belief becomes rational when, and only when, you have reason to believe that a 27-roll is favored by the structures involved in the game. And that belief, in its turn, is rational if you know that circumstances at all like the following obtain: *The dice are magnetically attracted to the 27-slot. *On any given occasion, you have an unconscious intention to roll a 27 (even though you have no conscious intention of doing this), and you're such a talented dice-thrower that, if you can roll a 27 if it is your (subconscious) intention to do so. *The 27-slot is much bigger than any of the other slots. In fact, it takes up so much space on the roulette wheel that the remaining spaces are too small for the ball to fit into them. You are rational to believe that you'll continue to roll 27s to the extent that your having thus far rolled multiple 27s in a row gives you reason to believe there to be some underlying structure favoring that outcome. And to the extent that a long run of 27-rolls doesn't give you such a reason, you are irrational to believe that you're any more (or any less) likely to roll a 27 than you are any other number. So, no matter how many consecutive 27s you roll, if you know with certainty that there is no underlying structure that would favor such an outcome, then you have no more reason to expect a 27 than you are a 5 or a 32. Put pedantically, it is only insofar as you have reason to believe in such a structure that you have reason to expect something that has the property of being a die thrown by you to have the property of landing in the 27-slot. Your knowing of many phi's that are psi's and of none that are not doesn't necessarily give you any reason to believe that the next phi you encounter will be a psi; it gives you such a reason only insofar as it gives you a reason to believe in some structure or mechanism that disposes phi's to be psi's. If you know on independent grounds that there is no such mechanism, no run of phi's that are psi's, no matter how long, gives you a reason to think that the next phi will be a psi. Thus, any case of induction by enumeration that isn't an instance of the gambler's fallacy involves the positing some mechanism or law that, were it to exist, would explain a certain concomitance—it involves, in other words, a case of inference to the best explanation. The best explanation of the fact that all known phi's are psi's is that, thanks to some mechanism or, in any case, principled connection of some kind or other, a thing's being a phi disposes it to be a psi. Hume's argument assumes that it is only through induction by enumeration that the past is any guide to the future. It assumes that, so far as we have any reason to believe that future phi's will be psi's, it is that past phi's have been psi's. But this assumption is dead wrong. The fact that past phi's were psi's, is not, in and of itself, reason to hold that future phi's will be psi's; it is such a reason only to the extent that it suggests some mechanism that disposes phi's to be psi's.

HUME, INDUCTION, AND THE LOGIC OF EXPLANATION 

We haven't yet refuted Hume's argument—we've only taken the first step towards doing so. Hume could defend his view against what we've said thus by far by saying the following: Suppose that, to explain why all phi's thus far known are psi's, you posit some underlying structure or law that disposes phi's to be psi's. Unless you think that nature is uniform, you have no right to expect that connection to continue to hold. But if, in order to deal with this, you suppose that nature is uniform, then you're caught in the vicious circle that I described. HR is correct. One is indeed caught in a vicious circle if, in order to show the legitimacy of inductive inference, one assumes UP; and the reason is that, just as Hume says, UP can be known, if at all, only on inductive grounds. But in making an inductive inference, one doesn't assume UP and, moreover, one doesn't assume anything that, like UP, can be known only on inductive grounds. What one assumes is that explanations are supposed to eliminate causal anomalies—that they are supposed to reduce the number of them and to limit the scope of those that aren't eliminated. What one assumes, then, is that it is inherent in the very concept of explanation that, other things being equal, T1 is a better explanation than T2 if T1 generates fewer anomalies than T2. The purpose of explanation is to minimize the breadth and depth of what must be taken for granted. The more a proposed theory requires you to say: 'things just happen that way; there's no explaining it,' the less successful an explanation it is. Here's an illustration. On Monday night, you park your car in the usual place, viz. right in front of your house, which is in a quiet residential neighborhood. As usual, you make sure that you lock the car and turn the car alarm on. You also put an almost, but not quite, indestructible device (popularly known as 'The Club') on the steering-wheel that locks it into place, making the car undriveable. Given where your home is in relation to where the car is parked, you'd almost certainly hear the car alarm if it went off. As it happens, you hear nothing all night. And you know that you didn't sleep any more deeply than usual—that, for example, you weren't in a particularly deep drug-induced slumber—and, in general, that you weren't made less sensitive to noise than you usually are. Nonetheless, on Tuesday morning, the car is gone. What are the various possible explanations of this? There are infinitely many; but here are three. (E1) Using his or her super powers to bypass the security measures you took, some superhero-like creature made off with the car, making little or no noise and leaving few or no clues. (E2) As you were sleeping, the laws of physics changed in such a way that hitherto noisy processes (e.g., those that occur when car alarms go off) are no longer noisy. (E3) Your good friend Larry—who, despite his numerous convictions for auto-theft, simply radiates trustworthiness and decency, and to whom, without so much as a touch of anxiety, you therefore gave copies of all your keys—made off with the car. Each of E1 and E2 replaces the mystery of how your car could be noiselessly stolen with a far greater mystery. In fact, each creates a whole network of deep mysteries. E3 is not free from sin either. In general, you are a good judge of character. In any case, that's what you believe and that's what others tell you; and your judgments about people have generally been borne out by subsequent events. You've never been as convinced of anyone's integrity as you are of Larry's. Without being morose or censorious, he exudes a decency and centeredness that you've never even seen in a head of state, let alone a car thief. But, of course, E3 is hands down the best explanation. You may think you're a good judge of character; but that doesn't mean you are one. People proverbially overestimate their ability to read others. And even if you are a good judge of character, so what? Anybody can be fooled; everybody is fooled, at some point or other. And if Larry is a career criminal—which, given his rap-sheet, he may well be—then he has probably honed his skills as a con-man. This doesn't mean that E3 is completely innocuous. If correct, it raises the question of how somebody could seem so different from how they are. It also raises the question of how, despite being a crime expert, you could have been unwary enough to let yourself be seduced into trusting somebody who, given his background, was so obviously unworthy of trust. But these mysteries can be dealt with more easily than the mysteries created by E1–E2. All of this goes to show that ceteris paribus the best explanation is the one that leaves us with the fewest unexplained explainers. Of course, new theories raise questions of their own. This is almost a tautology. A new theory is, tautologously, a new way of looking at things; and a new way of looking things is, very obviously if not tautologously, one that raises new questions. But good new theories tend to facilitate the answering of the questions they raise. Before proceeding, we must make a certain distinction very clear. Little or nothing about the actual causal structure of the world is analytic. It isn't analytic that there aren't giant causal gaps in the causal structure of the world; that reality doesn't consist of one ex nihilo event after another, that superheroes don't suddenly pop into existence, steal cars, and then, without leaving a trace, vanish never to be heard from again. These things, if known, are known only through sense-perception. But it isn't analytic that E3 is correct. It's a possibility—maybe only a bare theoretical possibility, but a possibility no less—that the laws of physics changed over night, that CIA super-agents have targeted you, that comic book characters now walk the Earth, etc. Anything's possible. And so far as we know that E1–E2 are wrong, it's through sense-perception. So, I repeat, it isn't analytic that E3 is correct. But, given that it requires fewer unexplained explainers than E1–E2, it is the best explanation.

EXPLANATORY GOODNESS VS. CORRECTNESS 

For an explanation to be good isn't for it to be correct. Sometimes the right explanations are bad ones. A story will make this clear. I'm on a bus. The bus driver is smiling. A mystery! 'What on Earth does he have to smile about?' I ask myself. His job is so boring, and his life must therefore be such a horror.' But then I remember that, just a minute ago, a disembarking passenger gave him fifty $100 bills as a tip. So I have my explanation: 'he just came into a lot of money.' But here is the very different explanation tendered by my seatmate Gus, who, in addition to being unintelligent, is also completely insane. 'The bus-driver is a CIA assassin. This morning he killed somebody who, by coincidence, had the name Benjamin Franklin. Benjamin Franklin (the statesman, not the murder victim) is on the $100 bill. So when the bus driver saw those bills, he immediately thought of that morning's murder. The murder was a particularly enjoyable one; the bus driver is remembering the fun he had, and that's why he's smiling.' Gus and I have access to the same empirical data. (Gus hasn't read the bus driver's diary; he doesn't know the bus driver any more intimately than I do; and so on.) And Gus doesn't have some sort of psychic gift that would give him access to otherwise unknowable facts about the bus driver's mind that would legitimize his explanation. Indeed, a belief that he has such a gift isn't even among Gus's many delusions. Nor does he have any good reason—even if, for argumentative purposes, we grant him his delusions—to believe what he believes. But Gus is right. His explanation is correct down to the last detail. Given that it turned out to be correct, should we say that, despite first appearances, Gus's explanation is not a bad one? No! It's a datum that it's bad. It's a bad explanation that turned out to be correct. Thus, for an explanation to be a good one isn't for it to be correct. But a short extension of our story illustrates the even stronger principle that for an explanation to be a good one isn't even for it to be likely to be correct. Let W be the real world and let W* be a hypothetical world where we have the exact same experiences that we have in W, but in which the Gus's of the world are always right. In W*, it's because Santa Claus is personally delivering gifts to millions of people that they suddenly appear in living rooms round the globe; it's because the Tooth Fairy is personally collecting teeth that they disappear from under pillows; and so on. Explanatory goodness is a relationship, not between explanations and reality, but between explanation and data. The relations that hold in W* between theory and data coincide with those holding in W. That's why the ones that are wrong in W* are no less good on that account. What is it that, in W*, makes wrong explanations be good? In general, what is the relationship that good theories bear with respect to the data?

KNOWLEDGE VS. AWARENESS

Knowledge is conceptually articulated awareness. In order for me to know that my shoes are uncomfortably tight, I need to have the concepts shoe, tight, discomfort, etc. I do not need to have these concepts—or, arguably, any concepts—to be aware of the uncomfortable tightness in my shoes. My knowledge of that truth is a conceptualization of my awareness of that state of affairs. Equivalently, there are two kinds of awareness: propositional and objectual. My visual perception of the dog in front of me is a case of objectual awareness, as is my awareness of the tightness of my shoes. My knowledge that there is a dog in front of me is a case of proposition-awareness, as is my knowledge that my shoes are uncomfortably tight. Truths, not objects, the objects of explanation. Observations are objectual awarenesses. The contents of such awarenesses must be converted into propositions if they are to be explained. This is because it is truths that are explained, and truths are true propositions. 'But don't we explain events?' it will be objected. 'Don't we explain bolts of lightning and avalanches?' To explain some avalanche or lightning-bolt x is to explain why it is a truth that x occurred. One is aware of lightning-bolts and avalanches. One explains the corresponding truths. Causal relations known through observation. Causal relations can be known only through one's senses (through sight, touch, etc.) and through real-time awareness of one's own psychological processes. In other words, causal relations can only be known empirically; and knowledge of them is therefore empirical. All theoretical knowledge inferential but not vice versa. Theoretical truths are necessarily known through inference, and knowledge of such truths is therefore inferential. But not all inferential knowledge is theoretical knowledge. I notice that you look tired and on that basis know that you didn't get enough sleep. That knowledge is inferential but non-theoretical. Theories and theoretical knowledge. A theory is given by a proposition that, if true, describes some relatively comprehensive fact about the structure of the universe. Theoretical knowledge is either (i) Knowledge of such a theory (e.g. your knowledge of evolutionary theory) or (ii) Knowledge that is derived from knowledge of such a theory (e.g. your knowledge that, the laws of mechanics being what they are and projectile x's state of motion being what it is, x will collide with surface y in approximately two hours). All knowledge justified true belief but not vice versa. If you know it, then (i) You believe it, (ii) It is true, and (iii) Your reasons for believing it are legitimate. At the same time, given only that it's true and that you are justified in believing it, it doesn't follow that you know it. A broken clock is right twice a day. If your belief that it's noon is based on the read-out of a broken clock, it isn't knowledge, even if that clock happens to be right and, in addition, you know it to be relatively reliable. Your belief would have been knowledge had you acquired it by virtue of being en rapport with the relevant realities; and the reason it wasn't knowledge is that it was not so acquired. For you to be en rapport with those realities