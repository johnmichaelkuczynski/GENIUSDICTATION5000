Hilbert-Bernays Paradox 

If there is a name of a natural number that is identical with the name of the successor that number, then some natural number is its own successor. 
The argument: Let h be a term referring to a such a natural number such that h is synonymous with ‘the reference of h+1’, and let n be the referent of h. Since h is synonymous with, and therefore has the same referent as ‘the referent of h+1’, it follows that the referent of h is n+1. And since n is by hypothesis the referent of h, it follows that n+n+1. 
Analysis: If h is synonymous with ‘the referent of h+1', then h is defined in terms of an expression that is itself defined in terms of h and h consequently has no referent. So h doesn’t refer to any number and a fortiori doesn’t refer to the successor of any number.

Heterological Paradox 

A word is ‘heterological’ if it is false of itself. Thus ‘monosyllabic’ is heterological, whereas ‘polysyllabic’ is not heterological. 
Question: Is ‘heterological’ heterological? It is if it isn’t and if isn’t if it is. 
Solution: To say that ‘polysyllabic’ is true of itself is to say that ‘polysyllabic’ is polysyllabic. To say that ‘is an English expression’ is true of itself is to say that ‘is an English expression' is an English expression. ‘True of itself,' when meaningful, simply abbreviates some non-reflexive construction; and when it doesn't do so, the term ‘self' an undefined pronoun—a free variable, in other words. The statement ‘the word “heterological” is true of itself’ does not abbreviate a non-reflexive construction, and neither does the sentence ‘the word “heterological” is heterological’; therefore, neither is either true or false.

The Sorites Paradox

A single grain of sand is not a heap. If n grains of sand, then neither are n+1 grains. Therefore, a billion grains of sands are not a heap.
Analysis: Three grains of sand is more of a heap than two; four are more of a heap than three. n+1 grains of sand are more ‘heapy’ than n grains. If, for arbitrary n, n grains of sand qualify as a heap, they do so because they are heapy enough relative to some benchmark. They may be heapy enough to alter the path of a rolling golf ball or they may be heapy enough to block traffic. 
There are infinitely many different Sorites paradoxes and they are all to be solved in more or less the same way. For example: A person who has only $1 is not rich. If a person with $n is not rich, neither is a person with $n+1. Therefore, a billionaire is not rich. Solution: A person with $n+1 is richer than one with only $n. If, for arbitrary n, a person with $n counts as ‘rich’, that is because he is rich relative to some benchmark. He may be rich enough to afford entry into a certain club or to fall into a certain tax bracket. 
Next example: If x is a given water-molecule and x is one mile away from cloud y, then x is not a part of y. If a water-molecule that is n millimeters away from a cloud is not a part of that cloud, then neither is a molecule that is n-1 millimeters away. Solution: Analysis: A water-molecule that is n-1 millimeters away from a given cloud is more a part of that cloud than an otherwise comparable one that is n millimeters away, in the sense that the first molecule's condition is relevant to the cloud's condition in a wider range of contexts than the second molecule. If, for arbitrary n, a water molecule that is n millimeters away from a given cloud ‘belongs' to that cloud, it is because it is close enough relative to some benchmark: it is sufficiently close that it was involved in the occurrence of some electrical storm that was otherwise the responsibility of that cloud or because it was involved in the slowing the descent of some object that was otherwise the responsibility of that cloud. 
In general, Sorites paradoxes are solved by replacing binary characterizations (‘heap’, ‘rich’, ‘part of a given cloud’) with the corresponding comparatives (‘more of a heap’, ‘rich’, ‘more a part of that cloud’), along with the contextually supplied benchmarks. n+1 straws are more of an unbearable load than n straws; and if a given number counts as an ‘unbearable load’, without being preceded by ‘more’ or some other comparative term, that is because that number of straws is unbearable enough in relation to some benchmark, for example, the camel’s back breaks if it has to carry that many straws. 

The Coin Paradox 

There are non-denumerably many regions R that a given coin dropped on a flat surface can occupy after settling. So if R* is the exact region that the coin does occupy, the chances of the coin’s occupying that exact region are 1 divided by the number of such regions and are therefore zero. But since the coin does occupy R*, the chances of its doing so are greater than zero.  
The solution: If an infinitely large class contains zero x’s, then the chances of choosing an x from that class are nil. If an infinitely large class contains one x, then the chances of choosing an x from that class are infinitesimally small but not nil.  

The Paradox of Analysis 

A conceptual analysis is given by a true, non-trivial and non-empirical proposition of the form x is a phi if and only if x is a psi, for example, ‘x is a circle if and only if x is a closed planar figure of uniform curvature.’ According to G.E. Moore, there is a ‘paradox of analysis,' for the reason that if a conceptual analysis is true, then both sides of the ‘if and only if' say the same thing, in which case said analysis is uninformative. So according to Moore, ‘x is a circle if and only if x is a closed planar figure of uniform curvature' is true only if ‘x is a circle' says the same thing as ‘x is a closed planar figure of uniform curvature'; but if they both say the same thing, Moore also holds, then ‘x is a circle if and only if x is a closed planar figure of uniform curvature' is uninformative.  
The solution is that the information-load borne by a statement is a function not only of what it says but how it says it. If I tell you that x is a closed planar figure of uniform curvature, the property that I am ascribing to x is the same as the property I’m ascribing to it if I say that x is a circle. But since the one ascription involves different concepts from the other and since in each case you must work through the concepts involved in the property-ascription to identify the property in question, the information borne by the one statement will differ from that borne by the other. 

The Paradox of the Incoherent Institution

If an institution exists to solve some problem, then it has an incentive to prevent that problem from being solved, since there will be no demand for that institution. So creating institutions to solve problems may prevent those problems from being solved. 
For example, philosophy departments supposedly exist to solve philosophical problems (or teach people how to solve them). But as anyone who has been in such a department knows, on the rare occasions that somebody comes along who actually has a solution, or even a fragment thereof, he is mercilessly attacked. 
To take another example: Departments that exist to help eliminate racial tensions exacerbate those tensions and create race-related problems where none existed. The same being true mutatis mutandis of women’s studies departments and gay studies departments. 
But not all institutions are like this. Hospitals exist to solve medical problems and they do solve them. 
The question is: What is the difference between an institution that solves the problems that it is meant to solve and an institution that prevents the solving of the problem that it is meant to solve? How does one know in advance whether a given institution will fall into the one category or the other? 
The answer seems to be this. If an institution stands to gain money by solving the problem that it is supposed to solve, then it will try to do so; and it stands to lose money by doing so, it will prevent it from it being solved. 
This raises the question: When is it profitable for an institution to solve a given problem and when it is not profitable? The answer to be this. A problem is profitable to solve if other problems take its place when it is solved and unprofitable to solve if they don’t. There are always more sick and injured people; and a hospital will get more future business if it does a good job with the patients that it has than if it doesn’t. There are not always more race-related problems or problems; so if a race-studies department actually eliminated racism, it would go out of existence. As for philosophical problems, there are always more philosophical problems, since philosophical problems are by-products of progress; but the intellectual instruments needed to solve a given philosophical problem are very often not those that are needed to solve the problems that would take its place were it to be solved. Advancing technology creates many new philosophical questions, but contemporary epistemologists would almost never even be able to recognize such problems, let alone solve them. So relative to the limitations of the people tasked with solving them, philosophical problems are the end-of-the-line, that being why philosophy departments are so inhospitable to attempts to solve the problems those same departments are supposed to solve. 



The Preface Paradox 

An author presumably believes each of the assertions in a book that he writes. But many books contain forward by the author in which he says that there are inevitably many false statements in the pages to come. How is this paradox to be solved? 
It is solved by pointing that the key premise is false: an author usually doesn’t believe everything that he writes in a given book. A book is not just a list of assertions. A book consists of assertions supported by arguments. Let us grant for argument’s sake that a given author believes the main assertions of a book that he writes. It doesn’t follow that he wholeheartedly believes in each of the arguments that he adduces on behalf of those assertions. He probably judges those arguments to be relatively probative. He also may well have doubts about many of them but believes that, the totality of the relevant data being what it is, those arguments are probably more probative than not. 
Much of what an author writes he writes not because he believes that it is true but because he believes that, the data being what it is, it must be true. 
Suppose that Smith is an author who writes a book that is just a bare list of indisputable assertions, along the lines of: 1+1=2, Paris is the Capital of France, apes are mammals, and the like. Will Smith write a preface in which he says that the pages to come contain false assertions? No, except as an empty gesture. And a very empty gesture it would be, since he obviously does believe in each of the statements he makes in that book. Contrariwise, when an author does disclaim the contents of some book of his, it is at least in part because he isn’t 100% confident in the accuracy of what it contains, the reason being much of what he writes he writes not because he knows it to be true but because he judges it to be warranted, which is very different from believing it to be true. And there is nothing paradoxical about the idea that one might make a judgement in which one is not completely confident. We make such judgements every day. When deciding who to hire, I have to choose between Smith and Jones. I have only limited information but have to make a judgment, so I make one. Am I sure that it’s correct? Not necessarily. I may be sure only that given the limited information at my disposal, along with my limited ability to analyze that data, I made the best that choice that I could. An author is often in a similar position, especially when he is writing a bona fide book of substance, as opposed to a mere recitation of facts.

Bhartrhari’s Paradox

The contention that some things cannot be described self-refutes, since in saying of something that it cannot be described, one is describing that thing. This is Bhartrhari’s Paradox. 
This paradox is based on a fallacy. Let S be the statement: “some things cannot be described.” There is no particular object x such that S says of x that x cannot be described. S makes a statement about a class of objects. It says that the class of indescribable objects is non-empty. There is no particular member of that class to which it ascribes the property of being indescribable. So there is no particular object to which S ascribes any property, and S therefore doesn’t self-refute. 
We have seen that S does not self-refute. But is S true? Yes and no. S is ambiguous, and one of its disambiguations is true and the is false. S can be taken to mean: Given any language L, there exist objects that cannot be described in L. Thus disambiguated, S is true. A language is a recursively defined expression-class and therefore contains denumerably many expressions. (A class is denumerably if it has the same number of members as the class of natural numbers.) There exist non-denumerably many real numbers. (A class is non-denumerable if it is larger than the class of natural numbers.) Therefore, for any language, there exist objects that cannot be referred to in L. 
S can also be taken to mean: There exist objects that cannot be described in any given language. Thus disambiguated, S is false, since given any object, there exists a possible language that can be refer to that object. 
So S not only fails to refute but is actually true on one of its disambiguations, and  Bhartrhari’s Paradox is not so much a real paradox as it is a logical blunder.

The Barber Paradox 

Consider a barber who shaves all and only those who do not shave themselves. Does that barber shave himself? If he does, then he doesn’t; and if he doesn’t, then he does. Conclusion: Such a barber cannot exist. That is what this paradox shows. 
Now consider the set of all sets that don’t contain themselves. If that set contains itself, then it doesn’t, and if doesn’t, then it does. Therefore, such a set cannot exist. 
Bertrand Russell believed this to prove the falsity of the so-called Axiom of Comprehension, this being the principle that any given property generates a set. The idea is that although the property of being a set of all sets that don’t self-contain exists, there is no corresponding set; so the Axiom of Comprehension is false. 
But the Axiom of Comprehension is correct, it being Russell’s reasoning that is off. To say that the class of humans doesn’t self-contain is to say that the set of humans is not a human. To say that the class of triangles doesn’t self-contain is to say that the set of triangles is not a triangle. In general, whenever it is meaningful, ‘S doesn’t self-contain’ is elliptical for some non-reflexive statement, the reason being that when it isn’t elliptical for such a statement it contains an undefined pronoun—a free-variable, in other words. And ‘the set of all sets that don’t contain themselves doesn’t contain itself’ is not elliptical for some non-reflexive statement and therefore isn’t significant, containing as it does an undefined pronoun and, consequently, a free variable.

Unexpected Hanging Paradox 

On Sunday, judge condemns Smith to be hanged some day the subsequent week on or before Friday, with the qualification that the day of the hanging will be a surprise to Smith. Smith deduces that he will not be hanged, his reasoning being as follows. He cannot be hanged on Friday, since, if he makes it to Friday, it won’t be a surprise to him that he is to hanged on that day. Nor therefore can be hanged on Thursday, since Friday has already been ruled out and since, if he makes it to Thursday, a Thursday-hanging won’t be a surprise to him. Nor, by parity of reasoning, can Smith be hanged on Wednesday, Tuesday, or Monday. So Smith won’t be hanged at all.  But Smith can be hanged under these circumstances.  
The solution to this paradox lies in the fact that ‘surprise’ is a relative term: what is a surprise to one person may not be a surprise to another; and what is a surprise to a person at one time may not be a surprise to him at a later time. When the judge tells Smith that the day of his hanging will be a ‘surprise’ to him, he is correctly saying that until the day of his hanging, Smith will not have enough information to determine the day of his hanging. And the judge is right. Smith does not have enough information now to know when he will be hanged. And if he is hanged on Monday, he won’t have the requisite information until Monday. Same with Tuesday, Wednesday, Thursday, and Friday. For any given day of the week, Smith will not know until that day whether or not he will be hanged on that day. So until the very day it occurs, Smith’s hanging is indeed a surprise to him, it being irrelevant that on that day Smith ceases to be surprised, since by then the surprise has in effect already occurred. 
	


Ross’s Paradox

If your room is clean, it follows that either your room is clean or the house has burned down. The strong entails the weak. But if I order you to clean your room, you are not complying if you either clean your room or burn down the house. Where ‘imperatival logic’ is concerned, the strong appears not to entail the weak. This asymmetry between alethic and imperatival logic is known as Ross’s Paradox. 
Why this asymmetry? Because whereas statements have a word-to-world direction of fit, meaning that the speech-act must conform to the world, imperatives have a world-to-word direction of fit, meaning that the world must conform to the speech-act. A consequence is that in the logic of imperatives, validity flows from the general to the specific, not from the specific to the general, as with statement-logic. If I tell you “either clean your room or burn down the house”, you are complying with my command if you burn down the house, since you have thereby created a state of affairs that validates the proposition expressed in my command (namely, you either you clean your room or burn down the house). Not so if I tell you, “clean your room” and you burn down the house. But if I correctly say “your room is clean”, the world has already supplied us with a state of affairs that validates “either your room is clean or the house has burned down.” 
To sum up: When direction-of-fit is from word-to-world, the general follows from the specific, but when direction-of-fit is from world-to-word, the specific follows from the general. 

The Lottery Paradox 

Suppose that there is a lottery in which 1,000 tickets are sold but only one ticket wins. It is rational regard to any given ticket as a loser. But if one does so, one must irrationally regard all of the tickets as losers. 
This is not much of a paradox. First of all, given any ticket, it cannot be rationally believed that it will lose, but only that it is more likely than not that it will lose. To be sure, in some contexts, high probabilities are interchangeable with certainties: if one knows that x is 99% likely to occur, then one can ‘accept’ x’s occurrence, in the sense that one will act and within limits even reason as though it will definitely occur. But in this particular context, as in others, high probabilities are not interchangeable with certainties and that is the end of it. 
It is not rational to believe (prior to the final lottery drawing) that a given ticket will lose, even though it is rational to believe it more likely than not that it will lose and to place one's bets accordingly. Acceptance is not belief. Acceptance is a pragmatic notion, and the legitimacy of a given case of acceptance is decided by its practical consequences. Belief is an alethic notion, and the legitimacy of a given case of belief is decided not by its practical consequences but by its correspondence with the truth.
A related point is that beliefs are not justified on strictly statistical grounds. If your belief that Smith is smart is justified, it is not justified on the basis of your knowledge that Smith belongs to a category 99% of whose members are smart. It is justified by its being more explanatory than its negation.

 
The Slacker’s Paradox 

People who try to avoid working end up working harder than people who don't try to avoid working. Case in point: People who work for pyramid schemes. These schemes never involve putting in time at an office, and one can work one's own hours. Also, theoretically, one can make an unlimited amount of money at one of these schemes doing very little work. But that isn't how it works out. People involved in such schemes end up putting in longer hours than people with real jobs and doing harder work, while being paid little or nothing.
This is not an isolated phenomenon. There are entire demographics of people whose professional lives are about avoiding work but who for that reason end up working far more than most people: street musicians, struggling actors, sex workers, and criminals. 
The solution to this paradox is that slackers are playing a defensive game. By spurning the normal rules of economic engagement, they are forced to take whatever opportunities come their way, which means that they aren’t deciding the terms of those transactions and are therefore constantly short-selling themselves, so that the have to work extra hard to make up the difference. 
People who are extremely successful don’t slack off, but they also don’t work excessively hard. And these two facts are related. They work mainly at choosing the kind of work that they do and spend relatively little of their energy doing work-proper. By contrast, less successful people, including drifters, do little in the way of deciding what kind of work they will do and commensurately more in the way of doing work-proper. 


The Paradox of Economic Efficiency

The more efficient an economy is, the less it depends on the work-input of any given person. The less it depends on any given person, the more useless to the economy any given person is and, consequently, the less able any given person is to find a way to earn a living by participating in it. So as economies become more efficient, people become more economically useless and therefore less able to earn a living and more dependent for their livelihood on welfare of some kind. Hence the following paradox: The more efficient an economy is, the more people tend to be prevented from profiting from it.  
	Let us put this in concrete terms. Until recently, audio editing, such as the editing involved in making this very audio book, had to be done almost entirely manually. Very little of the process was automated. Somebody had to physically splice the tape to edit out sounds. Another person had to be in charge of all of the splicing-relating technology. And so on. This meant a lot of jobs for a lot of people. All of those jobs are now gone, since sound-editing is now done by an app that costs around $30/year, as opposed to the $30/hour charged by some union sound-technician. Now that sound-editing can be done so cheaply, audio-products are less expensive than before and also available in greater number and variety. But all of those sound people are either excluded from the economy or they had to find entirely new lines of work. In most cases, they are living off of dwindling savings and are basically parasites. 
	And what is true of audio editing is true to varying degrees of many other economic sectors. Banking is largely automated. No more need for bank-tellers. Insurance-sales is largely automated. No more need for insurance salesman.  No more need for salesman of any kind. Nor is there is much of a need for supermarket cashiers. And the list goes on.
	Where do these people go? Further and further down, until they cannot live without handouts. So as the economy becomes more efficient, people become more useless to the economy and therefore less able to profitably engage the economy. 

The Raven Paradox

Presumably, logically equivalent statements are confirmationally equivalent. In other words, if two statements entail each other, then anything that one confirms the one statement to a given degree also confirms the other statement to that degree. But this actually seems false when consider statement-pairs such as: 

(i)	All ravens are black, 
and 
(ii)	All non-black things are non-ravens, 

which, though logically equivalent, seem to confirmationally equivalent, in that a non-black non-raven confirms (ii) to a high degree but confirms (i) to no degree or at most to a low degree. 
A number of very contrived solutions to this paradox have been proposed, all of which either deny that there is a paradox or invent ad hoc systems of logic to validate the ‘solution’ in question. 
But the real solution is clear. First of all, it is only principled generalizations that can be confirmed. Supposing that you assert (i) with the intention of affirming a principled as opposed to an accidental generalization, you are saying that instances of the property of being a raven grounds or causes instances of blackness. Read thus, (i) is most certainly not equivalent with (ii) or with any variation thereof. Be it noted that while there is a natural nomic or causal reading of (i), there is no such reading of (ii). Also be it noted that it is only principled as opposed to accidental generalizations that can be confirmed. “All metal expands when heated” can be confirmed but not “all objects in Smith’s  pocket expand when heated.” In general, when read as principled and therefore confirmable generalization, “all x’s are y’s” has nomic or causal content is therefore not equivalent with “all non-y’s are non-x’s.” Case closed on the Raven Paradox. 

The Riddle of Induction 

I cannot legitimately infer that x’s will lead to y’s from the fact they have done so thus far unless I know that what has happened will continue to happen, but I cannot know that what has happened will continue to happen unless I can legitimately infer that x’s will lead to y’s from the fact that they have do so thus far. Knowledge of the past provides no basis for knowledge of the future. 
Solution: When we know the future, it is on the basis of continuities, not regularities. For x to cause y is for y to be a continuation of x. It is not for x-like events to always precede y-like events. It is obviously to some extent on the basis of regularities that we know what causes what, but that is because regularities often tell us where to look for continuities---if I notice that the elevator comes every time I push a certain button, then I know where to look for a causal connection, meaning that I know where to look for a continuity. And until I have knowledge of such a continuity, I don’t have a good reason to believe that the elevator will come when the button is pushed. And once I do have knowledge of such a continuity, that is what serves as the basis for my being able to legitimately infer that the elevator will come after I push the button. And it so serves because, whereas discontinuity represent ex nihilo change, continuity represents preservation, and the legitimacy of the inference from cause to effect lies simply in the irrationality of positing spontaneities. 
	Of course, one often knows that x causes y without knowing exactly how y is continuous with x. One can know that pushing the button causes the elevator to come without knowing anything about the intervening electrical and mechanical events. But such a case, one knows of secondary continuities that require one to posit a continuity in the context in question. I know of continuities involving the activities of building-personnel and maintenance-staff and the like, and these continuities are not compatible with the supposition that there is a gap between the pushing of the button and the arrival of the elevator.  
	It follows that enumerative induction is either non-existent or illegitimate. When we make legitimate inferences as to the future, it is not on the basis of observation of repetitions; it is on the basis of knowledge of continuities. In some cases, knowledge of repetitions tells us where to look for continuities, but it never constitutes such knowledge. 
And—to introduce a new point—we may have knowledge of continuities without having knowledge of repetitions, this being why we may know that x caused y, even though we know of no other cases of x-like events being followed by y-like events. For example, if I see the ice-cube melt, then even if I have never previously seen anything melt, I can know that the melting of the ice-cube is responsible for the puddle on the counter.
	Given that knowledge of the future is not ultimately based on knowledge of past repetitions, it follows that Nelson Goodman’s so-called ‘new riddle of induction’, to which we now turn, is a non-riddle.


ALTERNATIVE ACCOUNT OF EXPLANATORY EFFICIENCY 

A continuation of the earlier case will make it clear what this means and why it matters. Why doesn't the outcome change under the given conditions? Because, says the standard account, the key factor remained in place. But, the skeptic will counter, perhaps we can discard that account; perhaps there's an alternative that fits the observations equally well. But, I would respond, even granting for argument's sake that such an alternative exists, it doesn't follow that it avoids more gaps than the one it replaces. It doesn't follow that it is comparable from a trade-off standpoint to the original—that it reduces as many issues as the old view while introducing no more new ones. In fact, the opposite often holds. Consider the alternative mentioned earlier. The cost of that account—meaning what new puzzles it creates—is vastly greater than its value—meaning what old puzzles it removes. It would be difficult to devise an account inconsistent with the conventional one that, while still matching the relevant evidence, is equally efficient in explanatory terms. You can test this for yourself. If there is reason to think even one such account exists, it is not because it has ever been produced. That reason, if it exists, must be purely theoretical. And for reasons soon to be made clear, no such purely theoretical reason can justify accepting it. But there is a further difficulty for this—or, by a similar line of thought, for any non-standard—replacement of the conventional view. It is not at all clear that, once the relevant details are considered, the replacement is even logically possible. Taken on its own, a substitute account may describe a situation that seems coherent. It may not be contradictory in the strict sense. But that alone is not enough for it to serve as a viable model of the relevant information. Think of the range of underlying principles that would have to be set aside. Setting them aside, if possible at all, would create ripple effects. Consider the various interactions that would be altered, the balances disrupted, the exchanges prevented. Those interactions do not only sustain the single feature in question. Removing them would have many other consequences—events unrelated to the specific aim of the new model. And there is no assurance that these other consequences would be compatible, even in a purely formal sense, with the data the new account is supposed to capture as well as the conventional one it seeks to replace.

EPISTEMOLOGY 

RATIONAL BELIEF AND UNDERLYING STRUCTURE 

When would it become rational to believe that, next time, you're more likely than not to roll this as opposed to that number—that, for example, you're especially likely to roll a 27? This belief becomes rational when, and only when, you have reason to believe that a 27-roll is favored by the structures involved in the game. And that belief, in its turn, is rational if you know that circumstances at all like the following obtain: *The dice are magnetically attracted to the 27-slot. *On any given occasion, you have an unconscious intention to roll a 27 (even though you have no conscious intention of doing this), and you're such a talented dice-thrower that, if you can roll a 27 if it is your (subconscious) intention to do so. *The 27-slot is much bigger than any of the other slots. In fact, it takes up so much space on the roulette wheel that the remaining spaces are too small for the ball to fit into them. You are rational to believe that you'll continue to roll 27s to the extent that your having thus far rolled multiple 27s in a row gives you reason to believe there to be some underlying structure favoring that outcome. And to the extent that a long run of 27-rolls doesn't give you such a reason, you are irrational to believe that you're any more (or any less) likely to roll a 27 than you are any other number. So, no matter how many consecutive 27s you roll, if you know with certainty that there is no underlying structure that would favor such an outcome, then you have no more reason to expect a 27 than you are a 5 or a 32. Put pedantically, it is only insofar as you have reason to believe in such a structure that you have reason to expect something that has the property of being a die thrown by you to have the property of landing in the 27-slot. Your knowing of many phi's that are psi's and of none that are not doesn't necessarily give you any reason to believe that the next phi you encounter will be a psi; it gives you such a reason only insofar as it gives you a reason to believe in some structure or mechanism that disposes phi's to be psi's. If you know on independent grounds that there is no such mechanism, no run of phi's that are psi's, no matter how long, gives you a reason to think that the next phi will be a psi. Thus, any case of induction by enumeration that isn't an instance of the gambler's fallacy involves the positing some mechanism or law that, were it to exist, would explain a certain concomitance—it involves, in other words, a case of inference to the best explanation. The best explanation of the fact that all known phi's are psi's is that, thanks to some mechanism or, in any case, principled connection of some kind or other, a thing's being a phi disposes it to be a psi. Hume's argument assumes that it is only through induction by enumeration that the past is any guide to the future. It assumes that, so far as we have any reason to believe that future phi's will be psi's, it is that past phi's have been psi's. But this assumption is dead wrong. The fact that past phi's were psi's, is not, in and of itself, reason to hold that future phi's will be psi's; it is such a reason only to the extent that it suggests some mechanism that disposes phi's to be psi's.

HUME, INDUCTION, AND THE LOGIC OF EXPLANATION 

We haven't yet refuted Hume's argument—we've only taken the first step towards doing so. Hume could defend his view against what we've said thus by far by saying the following: Suppose that, to explain why all phi's thus far known are psi's, you posit some underlying structure or law that disposes phi's to be psi's. Unless you think that nature is uniform, you have no right to expect that connection to continue to hold. But if, in order to deal with this, you suppose that nature is uniform, then you're caught in the vicious circle that I described. HR is correct. One is indeed caught in a vicious circle if, in order to show the legitimacy of inductive inference, one assumes UP; and the reason is that, just as Hume says, UP can be known, if at all, only on inductive grounds. But in making an inductive inference, one doesn't assume UP and, moreover, one doesn't assume anything that, like UP, can be known only on inductive grounds. What one assumes is that explanations are supposed to eliminate causal anomalies—that they are supposed to reduce the number of them and to limit the scope of those that aren't eliminated. What one assumes, then, is that it is inherent in the very concept of explanation that, other things being equal, T1 is a better explanation than T2 if T1 generates fewer anomalies than T2. The purpose of explanation is to minimize the breadth and depth of what must be taken for granted. The more a proposed theory requires you to say: 'things just happen that way; there's no explaining it,' the less successful an explanation it is. Here's an illustration. On Monday night, you park your car in the usual place, viz. right in front of your house, which is in a quiet residential neighborhood. As usual, you make sure that you lock the car and turn the car alarm on. You also put an almost, but not quite, indestructible device (popularly known as 'The Club') on the steering-wheel that locks it into place, making the car undriveable. Given where your home is in relation to where the car is parked, you'd almost certainly hear the car alarm if it went off. As it happens, you hear nothing all night. And you know that you didn't sleep any more deeply than usual—that, for example, you weren't in a particularly deep drug-induced slumber—and, in general, that you weren't made less sensitive to noise than you usually are. Nonetheless, on Tuesday morning, the car is gone. What are the various possible explanations of this? There are infinitely many; but here are three. (E1) Using his or her super powers to bypass the security measures you took, some superhero-like creature made off with the car, making little or no noise and leaving few or no clues. (E2) As you were sleeping, the laws of physics changed in such a way that hitherto noisy processes (e.g., those that occur when car alarms go off) are no longer noisy. (E3) Your good friend Larry—who, despite his numerous convictions for auto-theft, simply radiates trustworthiness and decency, and to whom, without so much as a touch of anxiety, you therefore gave copies of all your keys—made off with the car. Each of E1 and E2 replaces the mystery of how your car could be noiselessly stolen with a far greater mystery. In fact, each creates a whole network of deep mysteries. E3 is not free from sin either. In general, you are a good judge of character. In any case, that's what you believe and that's what others tell you; and your judgments about people have generally been borne out by subsequent events. You've never been as convinced of anyone's integrity as you are of Larry's. Without being morose or censorious, he exudes a decency and centeredness that you've never even seen in a head of state, let alone a car thief. But, of course, E3 is hands down the best explanation. You may think you're a good judge of character; but that doesn't mean you are one. People proverbially overestimate their ability to read others. And even if you are a good judge of character, so what? Anybody can be fooled; everybody is fooled, at some point or other. And if Larry is a career criminal—which, given his rap-sheet, he may well be—then he has probably honed his skills as a con-man. This doesn't mean that E3 is completely innocuous. If correct, it raises the question of how somebody could seem so different from how they are. It also raises the question of how, despite being a crime expert, you could have been unwary enough to let yourself be seduced into trusting somebody who, given his background, was so obviously unworthy of trust. But these mysteries can be dealt with more easily than the mysteries created by E1–E2. All of this goes to show that ceteris paribus the best explanation is the one that leaves us with the fewest unexplained explainers. Of course, new theories raise questions of their own. This is almost a tautology. A new theory is, tautologously, a new way of looking at things; and a new way of looking things is, very obviously if not tautologously, one that raises new questions. But good new theories tend to facilitate the answering of the questions they raise. Before proceeding, we must make a certain distinction very clear. Little or nothing about the actual causal structure of the world is analytic. It isn't analytic that there aren't giant causal gaps in the causal structure of the world; that reality doesn't consist of one ex nihilo event after another, that superheroes don't suddenly pop into existence, steal cars, and then, without leaving a trace, vanish never to be heard from again. These things, if known, are known only through sense-perception. But it isn't analytic that E3 is correct. It's a possibility—maybe only a bare theoretical possibility, but a possibility no less—that the laws of physics changed over night, that CIA super-agents have targeted you, that comic book characters now walk the Earth, etc. Anything's possible. And so far as we know that E1–E2 are wrong, it's through sense-perception. So, I repeat, it isn't analytic that E3 is correct. But, given that it requires fewer unexplained explainers than E1–E2, it is the best explanation.

EXPLANATORY GOODNESS VS. CORRECTNESS 

For an explanation to be good isn't for it to be correct. Sometimes the right explanations are bad ones. A story will make this clear. I'm on a bus. The bus driver is smiling. A mystery! 'What on Earth does he have to smile about?' I ask myself. His job is so boring, and his life must therefore be such a horror.' But then I remember that, just a minute ago, a disembarking passenger gave him fifty $100 bills as a tip. So I have my explanation: 'he just came into a lot of money.' But here is the very different explanation tendered by my seatmate Gus, who, in addition to being unintelligent, is also completely insane. 'The bus-driver is a CIA assassin. This morning he killed somebody who, by coincidence, had the name Benjamin Franklin. Benjamin Franklin (the statesman, not the murder victim) is on the $100 bill. So when the bus driver saw those bills, he immediately thought of that morning's murder. The murder was a particularly enjoyable one; the bus driver is remembering the fun he had, and that's why he's smiling.' Gus and I have access to the same empirical data. (Gus hasn't read the bus driver's diary; he doesn't know the bus driver any more intimately than I do; and so on.) And Gus doesn't have some sort of psychic gift that would give him access to otherwise unknowable facts about the bus driver's mind that would legitimize his explanation. Indeed, a belief that he has such a gift isn't even among Gus's many delusions. Nor does he have any good reason—even if, for argumentative purposes, we grant him his delusions—to believe what he believes. But Gus is right. His explanation is correct down to the last detail. Given that it turned out to be correct, should we say that, despite first appearances, Gus's explanation is not a bad one? No! It's a datum that it's bad. It's a bad explanation that turned out to be correct. Thus, for an explanation to be a good one isn't for it to be correct. But a short extension of our story illustrates the even stronger principle that for an explanation to be a good one isn't even for it to be likely to be correct. Let W be the real world and let W* be a hypothetical world where we have the exact same experiences that we have in W, but in which the Gus's of the world are always right. In W*, it's because Santa Claus is personally delivering gifts to millions of people that they suddenly appear in living rooms round the globe; it's because the Tooth Fairy is personally collecting teeth that they disappear from under pillows; and so on. Explanatory goodness is a relationship, not between explanations and reality, but between explanation and data. The relations that hold in W* between theory and data coincide with those holding in W. That's why the ones that are wrong in W* are no less good on that account. What is it that, in W*, makes wrong explanations be good? In general, what is the relationship that good theories bear with respect to the data?

KNOWLEDGE VS. AWARENESS

Knowledge is conceptually articulated awareness. In order for me to know that my shoes are uncomfortably tight, I need to have the concepts shoe, tight, discomfort, etc. I do not need to have these concepts—or, arguably, any concepts—to be aware of the uncomfortable tightness in my shoes. My knowledge of that truth is a conceptualization of my awareness of that state of affairs. Equivalently, there are two kinds of awareness: propositional and objectual. My visual perception of the dog in front of me is a case of objectual awareness, as is my awareness of the tightness of my shoes. My knowledge that there is a dog in front of me is a case of proposition-awareness, as is my knowledge that my shoes are uncomfortably tight. Truths, not objects, the objects of explanation. Observations are objectual awarenesses. The contents of such awarenesses must be converted into propositions if they are to be explained. This is because it is truths that are explained, and truths are true propositions. 'But don't we explain events?' it will be objected. 'Don't we explain bolts of lightning and avalanches?' To explain some avalanche or lightning-bolt x is to explain why it is a truth that x occurred. One is aware of lightning-bolts and avalanches. One explains the corresponding truths. Causal relations known through observation. Causal relations can be known only through one's senses (through sight, touch, etc.) and through real-time awareness of one's own psychological processes. In other words, causal relations can only be known empirically; and knowledge of them is therefore empirical. All theoretical knowledge inferential but not vice versa. Theoretical truths are necessarily known through inference, and knowledge of such truths is therefore inferential. But not all inferential knowledge is theoretical knowledge. I notice that you look tired and on that basis know that you didn't get enough sleep. That knowledge is inferential but non-theoretical. Theories and theoretical knowledge. A theory is given by a proposition that, if true, describes some relatively comprehensive fact about the structure of the universe. Theoretical knowledge is either (i) Knowledge of such a theory (e.g. your knowledge of evolutionary theory) or (ii) Knowledge that is derived from knowledge of such a theory (e.g. your knowledge that, the laws of mechanics being what they are and projectile x's state of motion being what it is, x will collide with surface y in approximately two hours). All knowledge justified true belief but not vice versa. If you know it, then (i) You believe it, (ii) It is true, and (iii) Your reasons for believing it are legitimate. At the same time, given only that it's true and that you are justified in believing it, it doesn't follow that you know it. A broken clock is right twice a day. If your belief that it's noon is based on the read-out of a broken clock, it isn't knowledge, even if that clock happens to be right and, in addition, you know it to be relatively reliable. Your belief would have been knowledge had you acquired it by virtue of being en rapport with the relevant realities; and the reason it wasn't knowledge is that it was not so acquired. For you to be en rapport with those realities